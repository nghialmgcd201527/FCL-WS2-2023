[
{
	"uri": "/",
	"title": "AWS Serverless SaaS Workshop",
	"tags": [],
	"description": "",
	"content": "AWS Serverless SaaS Workshop Overview In this workshop, we will build a Software-as-a-Service (SaaS) solution using AWS serverless services like Amazon API Gateway, Amazon Cognito, AWS Lambda, Amazon DynamoDB and Amazon CloudWatch. Our goal is to make it possible for SaaS developers and architectures working with code to understand how to design and migrate to a SaaS solution on AWS.\nThis workshop was written based on the SaaS Factory Serverless SaaS reference solution. At the end of this workshop, you will be able to build a SaaS application with all the functions of the reference solution above. It is worth noting in this workshop that you do not need to understand reference solution before. You just need to follow the instructions, step by step and carefully read the explanations, it will be easy to understand and grasp this reference solution.\nThe following figure is a structural diagram of the above reference solution.\nNội dung Introduction Prerequisite Introducing a basic serverless web application Introducing SaaS shared services Onboarding application Summary Cleanup "
},
{
	"uri": "/2-prerequiste/2.1-createcloud9workspace/",
	"title": "Create a new Cloud9 IDE",
	"tags": [],
	"description": "",
	"content": "Creating a new Cloud9 IDE Type Cloud9 in the service search bar on the AWS Console then select Cloud9. Choose Create environment Name the Cloud9 Workspace saas-workshop. In the Description field, enter the purpose you want to use in this workspace. Enter Saas workshop with serverless Environment type, here we will create a server to run this Cloud9 workspace. I will choose New EC2 instance option to create a new server. Go to settings for New EC2 instance, select Additional instance types then we choose t3.large. Keep the defaults for other settings. Click the Create. button Wait about 10 minutes for Cloud9 Workspace to be created. Once the Cloud9 Workspace is created, we will have an environment to work with the AWS CLI and other tools. In the list of Environments created, find the serverless-workshop environment and click the Open button to open the Cloud9 environment. After the environment opens, let\u0026rsquo;s close the sections below that were initialized at the start and create a new terminal page. Make sure you have turned off all the tabs that existed when we opened the Cloud9 IDE before we perform any activity, click the X button to disable that tab. This is essential to ensure that the next step of installing the tools needed for this workshop will not be affected.\nOur workspace will look like this.\n"
},
{
	"uri": "/3-serverless/3.1-deploy/",
	"title": "Deploy the application",
	"tags": [],
	"description": "",
	"content": "\rIn the previous step, you were provided with documentation to learn the structure and deployment of a serverless application with the SAM template here. In this article we will skip those steps in detail and just run the script file.\nLet\u0026rsquo;s deploy the serverless application by using the deployment.sh script file in the /environment/aws-serverless-saas-workshop/Lab1/scripts directory, and run the following command in the Cloud9 terminal.\n1| cd ~/environment/aws-serverless-saas-workshop/Lab1/scripts/\r2| ./deployment.sh -s -c --stack-name serverless-saas-workshop-lab1 We will wait about 5 to 8 minutes for the script to complete. In the above statement, the parameters -c and -s here indicate that we are deploying both server and client side code. After running the script completes, it will display the application\u0026rsquo;s URL as shown.\nIf you accidentally close the terminal page and just run the script, then go back to the /environment/aws-serverless-saas-workshop/Lab1/scripts directory, then run the command ./geturl.sh \u0026lt;stack_name\u0026gt; . \u0026lt;stack_name\u0026gt; here is the name of the stack that you created when running the script above.\nCheck created stack in CloudFormation Type CloudFormation in the service search bar on the AWS Console then select CloudFormation.\nIn the left navigation bar, we select Stacks. Here will show a list of stacks and we will see our stack named serverless-saas-workshop-lab1 just installed create.\nCheck created S3 bucket Type S3 in the service search bar on the AWS Console then select S3.\nWe will see two S3 buckets just created to store our application\u0026rsquo;s resources.\nTest the application\u0026rsquo;s URL Copy the URL of the application and paste it into the browser you are using, you will see the interface as shown below.\nSo we have successfully deployed our serverless application. In the next step, we will add data to the application and explore its working structure.\n"
},
{
	"uri": "/4-saas/4.1-ini/",
	"title": "Initialize the project",
	"tags": [],
	"description": "",
	"content": "In the previous step, we learned the structure and how to deploy a serverless application with SAM template here\nIn this step, we will initialize the project before going into the details of its structure. Let\u0026rsquo;s run the command below to initialize the project. Please pass the email address value, it will be used to get the information used to login to the admin application.\ncd ~/environment/aws-serverless-saas-workshop/Lab2/scripts/\r./deployment.sh -s -c --email \u0026lt;email address\u0026gt; Let\u0026rsquo;s go to the next step while the script is executing. Click the Next button.\nThe script file will send login information to the admin to the email address you provided above.\nWhen the script file executes successfully, we will get two paths Admin site URL and Landing site URL as shown below.\nWe copy and paste the URL of Admin site. Enter username and password sent to our email to login.\nAt the step the system asks us to reset the password, in order for our password to be validated, please include a capital letter and a special character.\nThe application interface for admin will be as shown below.\nAnd the interface of landing site will be as shown below.\n"
},
{
	"uri": "/1-introduce/",
	"title": "Introduction",
	"tags": [],
	"description": "",
	"content": "Before we dive into the code, the first thing we need to do is understand the structure created while building a solution SaaS-based. In this section will take us to ideas to later implement the designs we make ourselves and can better understand what we build in this workshop. We will explore why serverless is suitable for use in this model and what serverless services are used during the workshop.\nNội dung What is unique about SaaS-based delivery model? Why Serverless? What you will build AWS Serverless services used Prior knowledge "
},
{
	"uri": "/5-onboarding/5.1-onboardingadmin/",
	"title": "Onboarding SaaS admin application",
	"tags": [],
	"description": "",
	"content": "Now that our shared services are deployed, we can introduce our tenants to our application. This solution actually supports two separate flows for onboarding tenants. The first one we will look at here is triggered from the SaaS admin application. This model is often used in environments where the system does not support the self-service onboarding model.\nOnboarding SaaS admin site First, copy the URL of the SaaS Admin application included in the incoming email.\nPaste that URL and run it in your browser. You will see the login page as shown below.\nDuring the deployment of our application in the previous step, you were provided with username and password in the email sent to you. You must reset your password if you login for the first time, the username will be admin-user.\nOnce you have successfully logged in, it will display the application\u0026rsquo;s interface in the Dashboard page.\nIn the left navigation bar, select the item Tenants it will display the list of tenants that have been onboarded as shown below. The list will be empty because we currently don\u0026rsquo;t have any tenants onboard. Now, click the Add Tenant button.\nYou will see the form to fill in information as below. Name the tenant test tenant 1, making sure to provide an email address that you can access. You can provide the same email address you used to admin by adding +tenant1 to the suffix. As the email registered for the admin before was lmnghia911@gmail.com, now enter the email as lmnghia911+tenant1@gmail.com. This email will be used to provide tenant admin user is in the Amazon Cognito User Pool. Additionally a Cognito User group is created for this new tenant. Cognito will email temporary credentials to tenant admin users. Press the Submit button to start the process.\nAfter successfully creating the tenant, it will be displayed in the list as shown below.\n"
},
{
	"uri": "/1-introduce/1.1-whatsaas/",
	"title": "What is unique about SaaS-based delivery model?",
	"tags": [],
	"description": "",
	"content": "Software-as-a-Service (SaaS) is a business and software delivery model that enables organizations to offer their solution in a low-friction, service-centric approach. The SaaS model relies on agility and operational efficiency as pillars of a business strategy that promotes growth, reach, and innovation.\nWhile there are many business challenges to be solved, there are a few key architectural aspects that are essential to the success of SaaS-based delivery model. Below are some of the fundamental challenges you will encounter while architecting and building a SaaS based solution. Our goal here is to address these challenges as we step through the labs inside this workshop.\nAgility While architecting your solution, you should choose technologies that allow you to respond faster to ever-changing customer requirements and market conditions. In this workshop you will see how Serverless services allow us to move faster and remove the heavy lifting of managing the infrastructure.\nAutomated Onboarding This workshop aims at providing mechanisms to automate your customer onboarding experience. This will be essential to meet the growing needs of your business.\nIdentity managment This workshop provides a way for your tenants and users to interact with your system in a secure way. This is achieved by building an identity management system that lets you store and authenticate users in a tenant-aware fashion.\n"
},
{
	"uri": "/3-serverless/3.2-adddata/",
	"title": "Adding data and exploring the",
	"tags": [],
	"description": "",
	"content": "First we will go to the API Gateway Console, enter API Gateway in the service search bar on the AWS Console then select API Gateway.\nIt will take us to the page that lists the APIs that have been created. We will see that there is an API named serverless-saas-workshop-lab1 created from the script file deployment.sh in the previous step.\nCopy the ID of this API. Click on that API\u0026rsquo;s name to see the details of how we integrated API Gateway with Lambda functions. You can see by clicking on different methods like POST, GET, PUT and will see each method associated with its Lamba function. This allows you to scale each Lambda independently without affecting other Lambda functions.\nAs shown below, we click on the POST method, it will show the operation of this method.\nNext we will add the product to the system using the API provided by API Gateway. Return to the Cloud9 terminal, copy the below command, which will issue a POST REST call to the API and add a new product to the system. We will replace api-id and region with the ID value of the API we just copied and the region we are operating in.\ncurl -X POST https://\u0026lt;api-id\u0026gt;.execute-api.\u0026lt;region\u0026gt;.amazonaws.com/prod/product -H \u0026#39;Content-Type: application/json\u0026#39; -d \u0026#39;{\u0026#34;category\u0026#34;: \u0026#34;category1\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;Lamborghini\u0026#34;, \u0026#34;price\u0026#34;: \u0026#34;1000\u0026#34;, \u0026#34;sku\u0026#34;: \u0026#34;dollar\u0026#34;}\u0026#39; We will see something like this:\nNow, let\u0026rsquo;s check the Amazon DynamoDB table again and see the data that was added after the above command was executed successfully.\nType DynamoDB in the service search bar on the AWS Console then select DynamoDB.\nIn the left navigation bar, we select Tables. Here will show a list of tables and we will see all created tables as Order-Lab1 and Product-Lab1.\nClick on the table Product-Lab1, then click on Explore table items on the right side. To view the data in the table.\nAnd we will see the data we just added after running the above statement in Items returned.\nFinally, we will check in CloudWatch to see the logs generated when calling the API. Type CloudWatch in the service search bar on the AWS Console then select DynamoDB.\nIn the left navigation bar, we select Log groups in the Logs. section and select the log group whose name includes the phrase CreateProductFunction.\nThen we go down to Log streams, click on the log stream that was created when calling the API.\nFinally, we will select Timestamp which will include the data we add when calling the API.\nWhen you see the picture, we have successfully added data to the system and received logs about this activity.\n"
},
{
	"uri": "/4-saas/4.2-misscode/",
	"title": "Adding the missing code",
	"tags": [],
	"description": "",
	"content": "Review the code in the IDE Before we start modifying the application and adding/changing code, let’s look at how the code is organized in the Cloud9 IDE.\nIn your IDE, open folder Lab2, we will see foler server. There is new folder TenantManagementService. This folder contains code of our shared services it represents for various microservices used to support the horizontal requirements of the serverless SaaS solution. It includes registration service, tenant management service, and user management service. With each file on this list written in Python with Lambda functions as part of microservices. In the Lab2/server folder, we also see a Resource folder containing the file shared_service_authorizer.py. This file will include the code of the lambda authorizer, which is used for API Gateway to authenticate the SaaS admin application. Finally, look at the nested_templates subfolder and see how we break down our application from the template file into smaller files that are easy to manage and maintain. And now the template.yaml file uses these files to deploy infrastructure. It allows us to break down the infrastructure code into smaller pieces that are easier to manage. Now we are going to finalize the code for our application.\nTenant Management Service Let\u0026rsquo;s go to the Lab2/server/TenantManagementService folder and open the tenant-management.py file in your IDE and find the get_tenant. method this lambda function is used by the GET method of API Gateway /tenant to get all tenant details. This method has not been executed yet, we execute this method to retrieve data from DynamoDB table and return the result to UI. You can use the code below and add the get_tenant function we found to accomplish.\ndef get_tenant(event, context):\rtenant_id = event[\u0026#39;pathParameters\u0026#39;][\u0026#39;tenantid\u0026#39;]\rlogger.info(\u0026#34;Request received to get tenant details\u0026#34;)\rtenant_details = table_tenant_details.get_item(\rKey={\r\u0026#39;tenantId\u0026#39;: tenant_id,\r},\rAttributesToGet=[\r\u0026#39;tenantName\u0026#39;,\r\u0026#39;tenantAddress\u0026#39;,\r\u0026#39;tenantEmail\u0026#39;,\r\u0026#39;tenantPhone\u0026#39;\r]\r)\ritem = tenant_details[\u0026#39;Item\u0026#39;]\rtenant_info = TenantInfo(item[\u0026#39;tenantName\u0026#39;], item[\u0026#39;tenantAddress\u0026#39;],item[\u0026#39;tenantEmail\u0026#39;], item[\u0026#39;tenantPhone\u0026#39;])\rlogger.info(tenant_info)\rlogger.info(\u0026#34;Request completed to get tenant details\u0026#34;)\rreturn utils.create_success_response(tenant_info.__dict__) You will see we used tenant_id to retrieve data from the tenant_details table and return the result. You can see we used AttributesToGet to specify the attributes we want to get from the table. You can add other attributes if needed.\nUser Management Service Similar to the above, we will do the same with the create_user method in the user-management.py file in the Lab2/server/TenantManagementService directory.\ndef create_user(event, context):\ruser_details = json.loads(event[\u0026#39;body\u0026#39;])\rlogger.info(\u0026#34;Request received to create new user\u0026#34;)\rlogger.info(event)\rtenant_id = user_details[\u0026#39;tenantId\u0026#39;]\rresponse = client.admin_create_user(\rUsername=user_details[\u0026#39;userName\u0026#39;],\rUserPoolId=user_pool_id,\rForceAliasCreation=True,\rUserAttributes=[\r{\r\u0026#39;Name\u0026#39;: \u0026#39;email\u0026#39;,\r\u0026#39;Value\u0026#39;: user_details[\u0026#39;userEmail\u0026#39;]\r},\r{\r\u0026#39;Name\u0026#39;: \u0026#39;custom:userRole\u0026#39;,\r\u0026#39;Value\u0026#39;: user_details[\u0026#39;userRole\u0026#39;]\r},\r{\r\u0026#39;Name\u0026#39;: \u0026#39;custom:tenantId\u0026#39;,\r\u0026#39;Value\u0026#39;: tenant_id\r}\r]\r)\rlogger.info(response)\ruser_mgmt = UserManagement()\ruser_mgmt.add_user_to_group(user_pool_id, user_details[\u0026#39;userName\u0026#39;], tenant_id)\rresponse_mapping = user_mgmt.create_user_tenant_mapping(user_details[\u0026#39;userName\u0026#39;], tenant_id)\rlogger.info(\u0026#34;Request completed to create new user \u0026#34;)\rreturn utils.create_success_response(\u0026#34;New user created\u0026#34;) You\u0026rsquo;ll see we used user_details to get the user\u0026rsquo;s information from the request body and used tenant_id to add the user to the tenant\u0026rsquo;s group. You can add other attributes if needed. Notice how tenantId and userRole are stored as custom attributes.\nRegistration Service In service Registration is the service that coordinates the onboarding flow. The Registration service is invoked through the API Gateway as a public endpoint. This is by design because new tenants cannot be authenticated. However, the endpoints used to create tenant admins and tenants are protected by API Gateway resource policies capabilitty. These endpoints can only be called from the Tenant Registration service.\nCurrently, the register_tenant method in the tenant_registration.py file in the Lab2/server/TenantManagementService directory is empty. Find this method and add the code below.\ndef register_tenant(event, context):\rtry:\rtenant_id = uuid.uuid1().hex\rtenant_details = json.loads(event[\u0026#39;body\u0026#39;])\rtenant_details[\u0026#39;tenantId\u0026#39;] = tenant_id\rlogger.info(tenant_details)\rstage_name = event[\u0026#39;requestContext\u0026#39;][\u0026#39;stage\u0026#39;]\rhost = event[\u0026#39;headers\u0026#39;][\u0026#39;Host\u0026#39;]\rauth = utils.get_auth(host, region)\rheaders = utils.get_headers(event)\rcreate_user_response = __create_tenant_admin_user(tenant_details, headers, auth, host, stage_name)\rlogger.info (create_user_response)\rtenant_details[\u0026#39;tenantAdminUserName\u0026#39;] = create_user_response[\u0026#39;message\u0026#39;][\u0026#39;tenantAdminUserName\u0026#39;]\rcreate_tenant_response = __create_tenant(tenant_details, headers, auth, host, stage_name)\rlogger.info (create_tenant_response)\rexcept Exception as e:\rlogger.error(\u0026#39;Error registering a new tenant\u0026#39;)\rraise Exception(\u0026#39;Error registering a new tenant\u0026#39;, e)\relse:\rreturn utils.create_success_response(\u0026#34;You have been registered in our system\u0026#34;) You will see this code creates a tenant_id and adds tenant_details. Then it will call __create_tenant_admin_user and __create_tenant methods to create tenant admin and tenant. You can add other attributes if needed.\nRemember to save the edited files with the keyboard shortcut Ctrl+S or Cmd+S.\n"
},
{
	"uri": "/2-prerequiste/2.2-repodisk/",
	"title": "Increase free disk of Cloud9",
	"tags": [],
	"description": "",
	"content": "\rFirst, we will update to the latest version of the AWS CLI:\npip install --user --upgrade awscli aws-sam-cli On the terminal page on Cloud9, run the following command to clone Git repository aws-serverless-saas-workshop:\ngit clone https://github.com/aws-samples/aws-serverless-saas-workshop.git After running the above command, we will get as shown. We should see the aws-serverless-saas-workshop folder created.\nCheck free disk of Cloud9 instance By default, the free space of a Cloud9 instance is only about 2GB. Use the script below to avoid running out of space and problems during the workshop.\nGo to the aws-serverless-saas-workshop directory, check the size of the current volume with the following command:\ncd aws-serverless-saas-workshop\rdf -h We will get the result as shown below:\nfilesystem at the path /dev/nvme0n1p1 is the volume we are using. We will see that the free space of this Cloud9 instance is 3.6G. To avoid running out of space during the workshop, we are required to have a minimum of 50G for this workshop, start increasing the capacity of this Cloud9 instance to 50G.\nPlease go to the Cloud9Setup folder and open the script file increase-disk-size.sh with the following path:\ncd ~/environment/aws-serverless-saas-workshop/Cloud9Setup/ After opening the script file increase-disk-size.sh, we will see the content of the script used to increase the size:\nWe increase the capacity of the Cloud9 instance by running that script file:\n./increase-disk-size.sh After successful increment, we will get the output as shown:\nNow check the current capacity again with the following command:\ndf -h And we will see the results.\nAs we can see in the path /dev/nvme0n1p1, the current capacity of the Cloud9 instance has increased to 50G.\nOccasionally, even though the capacity of a Cloud9 instance has been increased to 50G, it may still show as 10G when you run the command df -h. In this case, restart the Cloud9 instance with sudo reboot and run df -h again to check.\n"
},
{
	"uri": "/5-onboarding/5.2-landing/",
	"title": "Onboarding the Sign-up application",
	"tags": [],
	"description": "",
	"content": "Tenants can also onboard in self-service mode. For this, we need a private application that represents a public-facing tool that can be used by customers as a tenant.\nIf unfortunately you accidentally close the terminal page and just run the script, then go back to the directory /environment/aws-serverless-saas-workshop/Lab2/scripts, then run the command ./geturl.sh it will will display the URL you need again.\nIn the step deploy the application again after the change, we already have the URL of the landing site. We copy it and paste it into the browser to run it. You will see the interface as shown below. This is a self-service page where you don\u0026rsquo;t need any credentials to take over a tenant.\nPlease click the Sign up now! button Then you will see a form as shown below. Name the tenant tenant2, select Plan as Standard and fill in the rest of the information in the form. Make sure to provide an email address that you can access. You can provide the same email address you used to admin by adding +tenant2 to the suffix. As the email registered for the admin before was lmnghia911@gmail.com, now enter the email as lmnghia911+tenant2@gmail.com. This email will be used to provide tenant admin user is in the Amazon Cognito User Pool. Additionally a Cognito User group is created for this new tenant. Cognito will email temporary credentials to tenant admin users. Press the Submit button to start the process.\nWhen the tenant is successfully onboarded, you will see a success message appear as shown below.\nGo back to the SaaS admin application, refresh the page and click on Tenants in the left navigation bar. You will see the new tenant appear here.\n"
},
{
	"uri": "/2-prerequiste/",
	"title": "Preparation ",
	"tags": [],
	"description": "",
	"content": "API Gateway - REST API In this step, you can use the Amazon API Gateway console to create and test a simple REST API with HTTP integration for your website.\nFor example, with the PeetStore website, the API will support methods for the client to access the backend of the website http://petstore-demo-endpoint.execute-api.com/petstore/pets\nGET / : allows accessing and reading data from the original API resource. API Gateway will respond with a data available in the store. GET /pests : allows to access and read data from the API resource /pets integrated with the backend /pets. Backend returns the available pets to the page in store. Here is an example when integrating with HTTP, the URL is named like this http://petstore-demo-endpoint.execute-api.com/petstore/pets POST /pets : allows to access and add data to API resources /pets integrated with backend name /petstore/pets. When the correct request is received , the backend will add the correct pets to the PetStore and return the results to the caller. It is also integrated vs HTTP. The API supports CORS access through optional methods of a built-in type called MOCK. API Gateways return headers that support CORS access. We will walk you through the steps to create and test an API from the example above using the API Gateway Console.\nCloud9 Workspace You can deploy your application from local environment if you want but I recommend you to use AWS Cloud9 integrated development environment (IDE).\nRemember that Cloud9 workspaces should only be created by an IAM user (or assigned to an appropriate IAM role) with Admin privileges, not a root user.\nWe often use the Integrated Development Environment (IDE) locally, in this workshop we will use Cloud9. It is an IDE that runs in the cloud using a browser, including the important, essential features in the local IDE that we often use such as writing, running, debugging code. Cloud9 already comes with bundles of files like JavaScript, Python, NodeJS and others here\nTo make AWS services more responsive, select the nearest Region during the workshop.\nContent Create a new Cloud9 IDE Increase free disk of Cloud9 Install necessary tools Setup CloudWatch log role ARN for API Gateway "
},
{
	"uri": "/1-introduce/1.2-whyserverless/",
	"title": "Why Serverless?",
	"tags": [],
	"description": "",
	"content": "AWS Serverless Services lets you focus on your SaaS solution, without managing servers. It addresses some of the concerns/challenges out-of-the-box in a SaaS-based delivery model.\nSaaS providers can go to market faster, since Serverless eliminates operational overhead. You only pay for what you use and this helps SaaS providers navigate through that initial transition period of on-boarding new tenants/customers. Serverless lets you scale as per tenant load. This is especially important, since initially you may not be able to predict how much load your tenants will be putting on your system. Eventually, SaaS providers are able to focus on their IP instead of worrying about scaling and managing their infrastructure.\n"
},
{
	"uri": "/4-saas/4.3-deploy/",
	"title": "Deploying the changes",
	"tags": [],
	"description": "",
	"content": "\rBe sure to save all changes from the previous step.\nAt this point the project initialization is complete, if it hasn\u0026rsquo;t finished yet then wait for it to complete before continuing. If interested, feel free to explore the code inside the TenantManagementService, foler that you didn\u0026rsquo;t see in the previous step.\nRun the command below to deploy the new code you just added in the previous files. Please note, in the deploy-updates.sh script file you will see that you are using the sam sync command to sync the updated code instead of redeploying all the stack again.\nRun the command below.\ncd ~/environment/aws-serverless-saas-workshop/Lab2/scripts\r./deploy-updates.sh After successful re-deployment, we will get the URL of Admin site and Landing site as shown below.\n"
},
{
	"uri": "/2-prerequiste/2.3-installtool/",
	"title": "Install necessary tools",
	"tags": [],
	"description": "",
	"content": "\rFirst, we will update to the latest version of the AWS CLI:\npip install --user --upgrade awscli aws-sam-cli Please go to the Cloud9Setup folder and open the pre-requisites.sh script file with the following path:\ncd ~/environment/aws-serverless-saas-workshop/Cloud9Setup/ After opening the pre-requisites.sh, script file, we will see the content of the script used to install all the necessary tools of this workshop:\nWe run that script file to install, it will take about 3 to 5 minutes to complete:\n./pre-requisites.sh The above script will download and upgrade the tools for your Cloud9 IDE:\nPython 3.8 AWS CLI AWS SAM AWS CDK CLI git-remote-codecommit Node and npm After running the completed script, we will see the result as shown below:\nNext, still in that path, we open the file pre-requisites-versions-check.sh :\nThe above script will check if the version of the tools installed above is suitable for this workshop. We run that script file to check:\n./pre-requisites-versions-check.sh Make sure your results get PASS for all installed and updated tools:\nSometimes, even though you have installed and updated the correct version, when you run the version check script but it still does not update, please restart the Cloud9 instance with the command sudo reboot and run the test script again that version.\n"
},
{
	"uri": "/3-serverless/",
	"title": "Introducing a basic serverless web application",
	"tags": [],
	"description": "",
	"content": "Overview The goal of this section is to introduce you to serverless web application basics and understand how AWS Serverless services interact with each other. We\u0026rsquo;ll start this step by familiarizing you with the moving parts of the environtment of Serverless web applications in general. In the following sections, you will use this web application to add the features needed to build our SaaS application.\nIn this section, we will use the Serverless Application Model (SAM) to build a backend process to handle requests from the web application. You will use Lambda function to perform each function that the application needs, each time the user sends a request, it will be called to execute. This function will store the data into DynamoDB, which will then send the response to the front-end and update it on the front-end. The function is called from the browser using Amazon API Gateway.\nWhat is SAM? Serverless Application Model (SAM) is an open-source framework that will make serverless application deployment easier. It provides a simple way to define serverless applications, and provides a set of tools for deploying those applications.\nIt allows us to specify the requirements of the application in code. SAM transforms and extends the SAM syntax to AWS Cloudformation to deploy your applications. You will see and use SAM templates throughout this workshop.\nHow does SAM work? AWS SAM is based on AWS Cloudformation. A serverless application is defined with a CloudFormation template and deployed with the CloudFormation stack. In short, the AWS SAM template is a CloudFormation template.\nAWS SAM defines a set of resources that describe common components of a serverless application. In order for AWS SAM to have objects defined in the CloudFormation template, the template must include a Transform section in the document root of AWS::Serverless-2016-10-31.\nIn this article, we won\u0026rsquo;t go into the analysis and deployment of a Serverless web application with SAM template, so if you don\u0026rsquo;t have any knowledge about SAM template then please refer here to understand the structure and content of the files that I will just run the script to This workshop does not take much time.\nBelow is the infrastructure architecture of this web application.\nWhen looking at this infrastructure, you will see we have a web application on the left side. It represents the application for the user to use and experience it. It will be accessed using the Amazon CloudFront distribution. This distribution will get the application\u0026rsquo;s resources from the Amazon S3 bucket. Our application accesses the environment\u0026rsquo;s microservices through the API Gateway. This API Gateway will process each request and route the traffic to the appropriate functions in each application\u0026rsquo;s microservices. For this example, we already have 2 e-commerce microservices, Product and Order, which are also provided with basic CRUD functions. Each of these services uses Amazon DynamoDB to store and manage data. Overall, this infrastructure architecture includes all the basic elements that make up a basic serverless web application. However, at this stage, this solution will not support multi-tenant. In the future, we will explore and improve the features serving multi-tenant.\nServerless microservices The concept of microservice may be a little different for a serverless environment. It is true that each function can be a microservice. However, it is more common to have a set of functions that represent a logical microservice. In this case, the microservice boundary is the API Gateway, supported by one or more Lambda functions. As in the above infrastructure, the Order service is divided into many functions like create, get, update and delete. These functions all operate on the same data and are grouped together into a logical microservice.\nFinally, we used Amazon DynamoDB to store our data and Amazon CloudWatch to store all the application logs.\nContent Deploy the application Adding data and exploring the architecture Review the code "
},
{
	"uri": "/3-serverless/3.3-reviewcode/",
	"title": "Review the code",
	"tags": [],
	"description": "",
	"content": "We will now look back at the code that was used to build and deploy our architecture.\nGo back to the IDE on Cloud9 and open the aws-serverless-saas-workshop folder. Expand the Lab1 folder, you will see 2 subfolders, client and server. The client directory includes code written in Angular for the front end.\nThe server directory contains the code used to deploy the AWS infrastructure. Inside the server folder, you\u0026rsquo;ll notice we have OrderService and ProductService folders that represent products and order microservices. Also note the template.yaml file will take care of deploying the infrastructure. This file is being deployed using Serverless Application Model (SAM), it is an open-source framework used to build and deploy serverless applications. In the server folder there is also a folder named layers, it contains the file logger.py deployed with Lambda Layers. Now all Lambda functions can share layers with each other for the purpose of logging logs in a centralized manner.\nNow that you have a basic understanding of the structure, let\u0026rsquo;s continue adding the necessary components to our SaaS application.\n"
},
{
	"uri": "/5-onboarding/5.3-data/",
	"title": "Reviewing the underlying data stores",
	"tags": [],
	"description": "",
	"content": "To understand more about what happens during registration, let\u0026rsquo;s take a look at how tenants and users data is stored.\nCognito User pools First, as we said earlier, this workshop uses Amazon Cognito to store user details. Let\u0026rsquo;s review the user pools created in Amazon Cognito.\nType Cognito in the service search bar on the AWS Console then select Cognito.\nThen in the left navigation bar, we select User pools. We will see the User pool name created in our workshop once the deployed script is complete. OperationUsers-ServerlessSaaSUserPool is used to store SaaS admin users and PooledTenant-ServerlessSaaSUserPool is used to store user information created during registration.\nWe select PooledTenant-ServerlessSaaSUserPool. Click on Users tab to see the available users.\nNext, we click on the Groups tab to see the available groups.\nGo back to the Users tab, click on any one of the tenant admin just created and notice the tenantId and custom role attributes added to this user. These custom properties allow us to create bindings between users and tenants. Whenever the user authenticates, the token returned includes these custom attributes, allowing easy access to the tenant\u0026rsquo;s context on the system. This context will play an important role in implementing data areas and tenant isolation in this workshop.\nDynamoDB Type DynamoDB in the service search bar on the AWS Console then select DynamoDB.\nIn the left navigation bar, we select Tables. It will show the list of tables created in the previous step. We choose ServerlessSaaS-TenantDetails.\nNext, we will click the Explore table items button to see the items stored in the table. In the Items returned, section, we will see that there are 2 previously created objects in this list.\n"
},
{
	"uri": "/1-introduce/1.3-whatbuild/",
	"title": "What you will build?",
	"tags": [],
	"description": "",
	"content": "The Labs in this workshop builds on top of each other, by adding components incrementally to achieve our end goal of building a fully functional SaaS application.\nBelow is the high-level architecture that you will be building in this workshop.\nAt a high level the architecture is broken down into three components.\nWeb applications You will be introduced to three different applications that interact with the backend services of the environment. Each of these applications are built with Angular.\nThe SaaS provider admin console represents an application that is used by the administrators of a SaaS provider. The Landing/sign-up application serves as a public facing registration page for new tenants to register themselves. The Sample SaaS commerce application represents a typical e-commerce application. It requires users to sign-in to access its features. Shared services You will see a set of shared services that are responsible for the onboarding, tenant, and user management aspects of the application. The name shared conveys the notion that these services are foundational to your SaaS environment, providing the cross-cutting functionality that is separate from your application services and shared across all the tenants. This means that all the operations and data that is used to onboard, manage, authenticate, and configure tenants are handled by these shared services.\nTo learn more about Share Services, see this document, here there will be a Q\u0026amp;A section to explain its hidden aspects\nApplication services (Tiered Deployment Model) Application services are a representation of the microservices that provide the business functionality of your application. In this solution, you’ll see that we support a tiered deployment model for these microservices. SaaS providers often are required to support a range of tiers that may have different requirements around isolation, noisy neighbor, performance, etc. The idea here is that we will use tiering considerations to support some of these requirements. We will use tenant tier to influence how microservices are deployed for a given tenant.\nYou will see that Basic, Standard, and Premium tier tenants will use a pooled model where AWS resources are shared by tenants. On the other hand, Platinum tier tenants are deployed with a Silo model. This means, each Platinum tier tenant enjoys their own set of AWS resources, that are not shared with any other tenant.\nTo learn more about Application Services, see this document, here there will be a Q\u0026amp;A section to explain its hidden aspects\n"
},
{
	"uri": "/1-introduce/1.4-serverlessused/",
	"title": "AWS Serverless services used",
	"tags": [],
	"description": "",
	"content": "Below are the list of AWS Services and features that this workshop uses:\nAWS Serverless Application Model (SAM) is an open-source framework for building serverless applications. It provides short syntax for implementing functions, APIs, databases, and event source mappings. With just a few lines per resource, you can define the application you want and the YAML usage pattern. During deployment, SAM transforms and extends the syntax into AWS CloudFormation allowing you to build serverless applications faster.\nAWS Cloud Development Kit (CDK) is an open-source software development framework for defining cloud infrastructure in code and provisioning it using AWS CloudFormation. It allows you to use programming languages like TypeScript, JavaScript, Python, Java, C#/.Net to define AWS resources in an application. The CDK will transform these programming languages into a CloudFormation template and deploy it to AWS.\nAmazon API Gateway is a fully managed service for creating, managing, monitoring, and securing APIs of any scale. It provides features such as API creation, publishing, maintenance, monitoring, securing and securing. It also allows you to create RESTful APIs and WebSocket APIs to transfer data at any scale.\nREST APIs is a type of API that uses HTTP requests to transmit data. REST APIs can transmit data in any format like JSON, XML, HTML, text, etc.\nLambda Authorizer is a way to secure REST APIs by using Lambda function to validate API requests. Lambda authorizers can be used to authenticate API requests using bearer tokens, request parameters, headers, and client certificates.\nUsage Plans is a way to manage your API requests. It allows you to manage API requests using API keys and rate limits.\nAPI keys is a way to secure REST APIs with How to use API keys. API keys can be used to secure REST APIs using API keys.\nAmazon Cognito is a fully managed service for authentication, user management, and user data synchronization across devices. It provides features like sign-up, sign-in, and access control for web and mobile applications. It also allows you to synchronize user data across devices.\nUser Pools is a way to authenticate and manage users. It provides features like sign-up, sign-in, and access control for web and mobile applications.\nAWS Lambda is a serverless compute service that allows you to run code without having to provision or manage servers. Lambda provides a way to run code without having to manage servers. It also provides features like auto scaling, high availability, and native integrations with several other AWS services.\nAmazon DynamoDB is a serverless key-value pair and a type of non-relational (Non-SQL) database that delivers millisecond performance at any scale. Similar to other databases, Amazon DynamoDB stores data in tables. In our application, we will store the information of the tasks in the table of DynamoDB. This table will be accessed by the Lambda function in response to the API from our web application.\nAdditionally, we have used Python as the programming language of choice here.\n"
},
{
	"uri": "/4-saas/",
	"title": "Introducing SaaS shared services",
	"tags": [],
	"description": "",
	"content": "Before we can start working with tenants, we need to introduce services that allow us to integrate, authenticate, and manage the environment. Services, called shared services that will provide common core functionality to all tenants will be managed and operated in our serverless SaaS solution. For this step, we will look at shared services and learn the code behind these services, filling in the gaps of the functionalities that need to be implemented. The following is a list of features that will be added in this step:\nIntroduce a sign-up application that all our tenants can self-register on our SaaS application. Introducing the SaaS admin console, it can be used to manage SaaS users, tenants and others. Add the idea of tenancy to our environment by introducing the shared services needed to register, authenticate, and manage the environment. Add more data storage to support user management and tenants management as part of our shared services. The architecture model below describes in general the architecture that we will build and deploy. The highlighted component with the orange frame is the area that we will add in this step to achieve the goal of this workshop.\nSaaS admin application The administration application is meant to represent the experience that would be used by a SaaS Provider. This application provides the management and operations experience for your environment and its tenants.\nLanding/Sign-up page The landing page is a simple, anonymous signup page. It\u0026rsquo;s representative of our public-facing marketing page through which prospective tenants can sign-up. When you select the sign-up option, you will provide data about your new tenant and submit that information to the system\u0026rsquo;s registration service. This service will then create and configure all the resources needed to introduce a new tenant into the system.\nShared services The shared services refer to the common set of services that are core to any SaaS environment. These services provide all the mechanisms that are needed to have a universal view of how tenants are onboarded, managed, and operated in SaaS environment.\nTenant registration The Tenant Registration service allows new tenants to register themselves and onboard to your SaaS application. There are a few moving parts to this registration experience. This Tenant Registration service is responsible for orchestrating interactions with user management and tenant management that are part of the onboarding experience.\nUser management The User Management service allows us to add, update, disable and get users. It also allows us to get all users, disable all users, and enable all users by tenant. The users, in this scenario, will be stored in Amazon Cognito.\nTenant management The Tenant Management service centralizes all of the configuration and operations that can be performed on a tenant. This includes get, create, update, activate, and disable tenant functionality. Tenant details are stored inside an Amazon DynamoDB table.\nTenant onboarding flow The diagram below depicts the tenant onboarding process and how Registration service leverages other services to orchestrate the flow.\nThe sign-up process for a tenant is a combination of a few steps. The tenant uses the sign-up application to access the registration page, where they provide their information along with the tier they intend to sign-up for. This kicks off the registration process by invoking the \u0026ldquo;registration\u0026rdquo; endpoint inside API Gateway, as shown in Step 1.\nStep 2 of the flow invokes the User Management service to create a new tenant admin user. We are using Amazon Cognito as our identity provider for this workshop. The User Management service will create a Cognito User Group inside the pooled user pool for that tenant. Finally, a tenant admin user is created for the tenant inside the user pool.\nAs part of creating the tenant admin user we must also associate this user with tenant specific attributes. This is achieved through Cognito\u0026rsquo;s custom attributes. These custom attributes store certain tenant and user specific information. For this solution we\u0026rsquo;ve stored TenantId and User Role as custom attributes.\nStep 3 will then call the Tenant Management service to store tenant details. We also store the user pool information for the tenant, based upon the data collected from the prior step.\nOne thing you might have noticed is that the tenant registration service doesn\u0026rsquo;t require any authentication. This is by design since new tenants are unable to be authenticated. However, the endpoints that are used to create a tenant admin, create a tenant, and provision a user are protected. These endpoints can only be invoked from the Tenant Registration service.\nTo keep these internal endpoints private and protected, we have used the API Gateway Resource Policies feature. These policies ensure that the private REST entry points of our services are not publicly accessible.\nContent Initialize the project Adding the missing code Deploying the changes "
},
{
	"uri": "/2-prerequiste/2.4-cloudwatch/",
	"title": "Setup CloudWatch log role ARN for API Gateway",
	"tags": [],
	"description": "",
	"content": "\rFirst, we will update to the latest version of the AWS CLI:\npip install --user --upgrade awscli aws-sam-cli In this step, in our AWS account, we will make sure the CloudWatch log ARN role is set up for API Gateway. You need this setup step to make sure API Gateway can log to CloudWatch so that you can debug API Gateway REST APIs errors.\nAPI Gateway - REST API Type API Gateway in the service search bar on the AWS Console then select API Gateway.\nIf this is your first time using API Gateway, you will see a page that introduces API Gateway features. Under REST API, select Build. When the Create Example API popup appears, select OK.\nIf this is not your first time using API Gateway, select Create API in the upper right corner of the page.\nOn the Choose an API type page, we choose REST API but not Private and choose Build.\nIn Choose the protocol page, we will choose its protocol, we choose REST, in Create new API, we choose Example API, it will An example API pops up, we can see the details of it.\nAnd finally press the Import, button it will create a new API.\nThe new API will be shown here as PetStore.\nTo know more about how to use that API, you will see here: Example REST API\nTạo CloudWatch role In the next step, we will create an ARN role that will allow CloudWatch to log how the action sends requests to the API.\nFirst we will go to the AWS Identity and Access Management (IAM) console, in the left navigation bar, we choose Roles.\nClick the Create role button.\nIn Create role, section Trusted entity type, we choose AWS service, in Use case, we will click on drop box Use cases for other AWS services, we choose API Gateway and press the Next button.\nOn the Add permissions, page we will see the AmazonAPIGatewayPushToCloudWatchLogs policy already selected. This policy has all the permissions we need.\nFinally on the page Name, review, and create, we name it in the Role name, here we will set it as cloudwatch-api. The other items we leave default, press the button Create role. So we have successfully created.\nGo back to the Role page, type in the search bar cloudwatch-api it will show the role you just created.\nWe click on the cloudwatch-api role to see details. We will see the ARN value of that role and copy it for the next step.\nGo back to the API Gateway console page, select the API named PetStore then in the left navigation bar, under Client Certificates, we choose Settings. In the CloudWatch log role ARN section, we paste the ARN of the cloudwatch-api role enter and press Save button.\nSo we\u0026rsquo;ve finished setting up the CloudWatch log role ARN for API Gateway. Let\u0026rsquo;s go to the next step.\n"
},
{
	"uri": "/5-onboarding/",
	"title": "Onboarding application",
	"tags": [],
	"description": "",
	"content": "Now that our shared services are deployed, we can introduce our tenants to our application. This solution actually supports two separate flows for onboarding tenants. The first one we will look at here is triggered from the SaaS admin application. This model is often used in environments where the system does not support the self-service onboarding model.\nTenants can also onboard in self-service mode. For this, we need a private application that represents a public-facing tool that can be used by customers as a tenant.\nContent Onboarding SaaS admin application Onboarding the Sign-up application Review the underlying data stores "
},
{
	"uri": "/1-introduce/1.5-prior/",
	"title": "Prior knowledge",
	"tags": [],
	"description": "",
	"content": "This workshop aims to provide case solutions for building SaaS-based applications using AWS Serverless services. Although not required, you will gain a lot of knowledge and experience from this workshop if you already have a basic knowledge of AWS and Serverless. For those who are new to Serverless on AWS, we will try to provide an overview of how to build a basic Serverless web application because this workshop is not focused on giving a thorough introduction to AWS Serverless services.\n"
},
{
	"uri": "/6-sum/",
	"title": "Summary",
	"tags": [],
	"description": "",
	"content": "In this workshop, we introduced the concepts of shared services and introduced some tenants in the pooled model. We also saw how user and tenant information is stored inside Cognito and DynamoDB. But at this stage, products and order microservices have no mechanism to track which tenant is trying to access the system and even how to partition data by business service by tenants.\n"
},
{
	"uri": "/7-terminate/",
	"title": "Cleanup",
	"tags": [],
	"description": "",
	"content": "Cloud9 instance We enter Cloud9 Console by entering Cloud9 in the service search bar on AWS Console and then selecting Cloud9. Select the Cloud9 you created in step 2.1 and press the Delete button in the upper right corner. Then enter Delete to confirm the deletion of this Cloud9 instance and press the Delete. button Wait a few minutes for the Cloud9 instance to be completely deleted.\nCloudFormation We enter CloudFormation Console by entering CloudFormation in the service search bar on AWS Console and then selecting CloudFormation. We will see a list of stacks created in this workshop. We select each one and press the Delete button in the upper right corner.\nFor the nested stacks, after pressing the Delete, button we will select the Delete nested stack option and enter delete to confirm. Finally, we press the Delete button.\nWait a few minutes, so we have cleared all stacks in CloudFormation.\nS3 Bucket We enter S3 Console by entering S3 in the service search bar on AWS Console and then selecting S3. We will see a list of buckets created in this workshop. We select each one and press the Delete button in the upper right corner.\nIf we get the message as shown then click on empty bucket configuration to empty the bucket before deleting it.\nFinally, we need to enter permanently delete to confirm the emptying of the bucket and press the Empty button. After emptying the bucket, we return to the buckets list page, select a bucket and press the button ** Delete** to delete the bucket. So we have successfully deleted the S3 bucket.\nCloudWatch Log Groups We enter CloudWatch Log Groups by entering CloudWatch in the service search bar on the AWS Console and then selecting CloudWatch. In the left navigation bar, we select Log groups, it will show a list of all the log groups created in this workshop. We select all the log groups created in this workshop, then press the Action button, select Delete log group(s) and press the Delete. button so we have deleted. success We will see the list of stacks created in this workshop. We select each one and press the Delete button in the upper right corner.\nSo we have deleted all the resources created in this workshop.\n"
},
{
	"uri": "/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]